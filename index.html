<!DOCTYPE HTML>
<html lang="en">

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shen Sang</title>

  <meta name="author" content="Shen Sang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="KWYLDUPbMWc0kQb2gP0dx5MmcOOUWG_3Y1IoFVITOME" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <!-- prfile -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shen Sang (桑燊)</name>
              </p>
              <p>
                I am a Senior Research Scientist, with a primary focus on virtual human and GenAI, at the Intelligent Creation Lab, TikTok.
              </p>
              <p>
                I received my master's degree from UC San Diego. I was fortunate to work with <a href="https://cseweb.ucsd.edu/~mkchandraker/">Prof. Manmohan Chandraker</a> at the Visual Computing Center.
              </p>
              <p style="text-align:center">
                <a href="https://github.com/ssangx">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=DkkblQQAAAAJ&hl=en&authuser=4&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/shen-sang-ab6b0217a/">LinkedIn</a>
              </p>
              <br>
              <p>
                Please feel free to contact me by email: shen.sang[at]bytedance[dot]com
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile3.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- news -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><b>News</b></heading>
              <p>
                [2025.02] <a href="https://byteaigc.github.io/coap/"> COAP</a> and <a href="https://byteaigc.github.io/ID-Patch/"> ID-Patch</a> are accepted to CVPR 2025. Code will be released soon.
              </p>
              <p>
                [2024.02] <a href="#tiktok-ai-self"> TikTok AI Self</a> has been launched and is available globally.
              </p>
              <p>
                [2023.07] <a target="_blank" href="https://jitengmu.github.io/ActorsNeRF">ActorsNeRF</a> is accepted to ICCV 2023.
              </p>
              <p>
                [2023.05] <a href="#tiktok-ai-avatars">TikTok AI Avatars</a> is launched globally.
              </p>
              <p>
                [2022.08] <a target="_blank" href="./projects/agileavatar/index.html">AgileAvatar</a> is accepted to SIGGRAPH Asia 2022.
              </p>
              <p>
                [2022.06] <a href="#tiktok-avatars">TikTok Avatars</a> is launched globally.
              </p>
            </td>
          </tr>
        </tbody></table>

        <!-- research title -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><b>Research</b></heading>
              <p>
                I work on human-specific image and video generation. My current research interests include customized video generation, personalized image generation with diffusion models, and enhancing the training and inference efficiency of these models. Previously, I worked on 3D vision and graphics, particularly in 3D reconstruction and neural relighting.
              </p>
            </td>
          </tr>
        </tbody></table>

        <!-- pub list -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src='images/pubs/2024-arxiv-coap.png' width="110%">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href=https://byteaigc.github.io/coap/>
                <papertitle>&#x2728 COAP: Memory-Efficient Training with Correlation-Aware Gradient Projection</papertitle>
              </a>
              <br>
                <a target="_blank" href="https://scholar.google.com/citations?user=ITSm2LYAAAAJ&hl=en">Jinqi Xiao</a>, 
                <strong>Shen Sang</strong>,
                <a target="_blank" href="https://tiancheng-zhi.github.io/">Tiancheng Zhi</a>, 
                <a target="_blank" href="https://www.jingliu.net/">Jing Liu</a>, 
                <a target="_blank" href="https://scholar.google.com/citations?user=0TIYjPAAAAAJ&hl=en">Qing Yan</a>, 
                <a target="_blank" href="https://linjieluo.github.io/">Linjie Luo</a>, 
                <a target="_blank" href="https://sites.google.com/site/boyuaneecs">Bo Yuan</a>
              <br>
              <br>
                <em>CVPR</em>, 2025
              <br>
              [<a target="_blank" href="https://byteaigc.github.io/coap/">project</a>]
              [<a target="_blank" href="https://arxiv.org/abs/2412.00071">arXiv</a>]
              [<a target="_blank" href="">code (coming soon)</a>]
            </td>
          </tr>
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src='images/pubs/2024-arxiv-idp.png' width="110%">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href=https://byteaigc.github.io/ID-Patch/>
                <papertitle>&#x2728 ID-Patch: Robust ID Association for Group Photo Personalization</papertitle>
              </a>
              <br>
                <a target="_blank" href="https://damon-demon.github.io/">Yimeng Zhang</a>, 
                <a target="_blank" href="https://tiancheng-zhi.github.io/">Tiancheng Zhi</a>, 
                <a target="_blank" href="https://www.jingliu.net/">Jing Liu</a>, 
                <strong>Shen Sang</strong>,
                <a target="_blank" href="https://liming-jiang.com/">Liming Jiang</a>, 
                <a target="_blank" href="https://scholar.google.com/citations?user=0TIYjPAAAAAJ&hl=en">Qing Yan</a>, 
                <a target="_blank" href="https://lsjxjtu.github.io/">Sijia Liu</a>, 
                <a target="_blank" href="https://linjieluo.github.io/">Linjie Luo</a>
              <br>
              <br>
                <em>CVPR</em>, 2025
              <br>
              [<a target="_blank" href="https://byteaigc.github.io/ID-Patch/">project</a>]
              [<a target="_blank" href="https://arxiv.org/abs/2411.13632">arXiv</a>]
              [<a target="_blank" href="">code (coming soon)</a>]
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src='images/pubs/2023-arxiv-actors-nerf.gif' width="110%">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href=https://jitengmu.github.io/ActorsNeRF/>
                <papertitle>ActorsNeRF: Animatable Few-shot Human Rendering with Generalizable NeRFs</papertitle>
              </a>
              <br>
                <a target="_blank" href="https://jitengmu.github.io/">Jiteng Mu</a>, 
                <strong>Shen Sang</strong>,
                <a target="_blank" href="http://www.svcl.ucsd.edu/~nuno/">Nuno Vasconcelos</a>, 
                <a target="_blank" href="https://xiaolonw.github.io/">Xiaolong Wang</a>
              <br>
              <br>
                <em>ICCV</em>, 2023
              <br>
              [<a target="_blank" href="https://jitengmu.github.io/ActorsNeRF/">project</a>]
              [<a target="_blank" href="https://arxiv.org/abs/2304.14401">arXiv</a>]
              [<a target="_blank" href="https://github.com/JitengMu/ActorsNeRF">code</a>]
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src='images/pubs/2022-sa-agile-avatar.gif' width="110%">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href=./projects/agileavatar/index.html>
                <papertitle>AgileAvatar: Stylized 3D Avatar Creation via Cascaded Domain Bridging</papertitle>
              </a>
              <br>
                <strong>Shen Sang</strong>,
                <a target="_blank" href="https://tiancheng-zhi.github.io">Tiancheng Zhi</a>, 
                <a target="_blank" href="https://guoxiansong.github.io/homepage/index.html">Guoxian Song</a>, 
                Minghao Liu,
                Chunpong Lai,
                <a target="_blank" href="https://www.jingliu.net/">Jing Liu</a>,
                Xiang Wen,
                <a target="_blank" href="https://users.soe.ucsc.edu/~davis/">James Davis</a>,
                <a target="_blank" href="https://linjieluo.github.io/">Linjie Luo</a>
              <br>
              <br>
                <em>SIGGRAPH Asia</em>, 2022
              <br>
              [<a target="_blank" href="https://ssangx.github.io/projects/agileavatar/index.html">project</a>]
              [<a target="_blank" href="pubs/2022-SIGGRAPHAsia-AgileAvatar.pdf">paper</a>]
              [<a target="_blank" href="https://arxiv.org/abs/2211.07818">arXiv</a>]
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src='images/pubs/2021-cvpr-openrooms.png' width="110%">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href="https://vilab-ucsd.github.io/ucsd-openrooms/">
                <papertitle>OpenRooms: An Open Framework for Photorealistic Indoor Scene Datasets</papertitle>
              </a>
              <br>
                <a target="_blank" href="https://sites.google.com/a/eng.ucsd.edu/zhengqinli">Zhengqin Li</a>, 
                Ting-Wei Yu, 
                <strong>Shen Sang</strong>, 
                Sarah Wang, 
                <a target="_blank" href="https://sites.google.com/site/mengsong1130/">Meng Song</a>, 
                Yuhan Liu, 
                <a target="_blank" href="https://yuyingyeh.github.io/"> Yu-Ying Yeh</a>, 
                <a target="_blank" href="https://jerrypiglet.github.io/">Rui Zhu</a>, 
                <a target="_blank" href="https://scholar.google.com/citations?user=v19p_0oAAAAJ&hl=en">Nitesh Gundavarapu</a>, 
                Jia Shi, 
                <a target="_blank" href="https://sai-bi.github.io/">Sai Bi</a>, 
                <a target="_blank" href="https://cseweb.ucsd.edu/~zex014/">Zexiang Xu</a>, 
                <a target="_blank" href="https://kovenyu.com/">Hong-Xing Yu</a>, 
                <a target="_blank" href="http://www.kalyans.org/">Kalyan Sunkavalli</a>, 
                <a target="_blank" href="http://www.miloshasan.net/">Miloš Hašan</a>, 
                <a target="_blank" href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
                <a target="_blank" href="https://cseweb.ucsd.edu/~mkchandraker/">Manmohan Chandraker</a>
              <br>
              <br>
                <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              [<a target="_blank" href="https://vilab-ucsd.github.io/ucsd-openrooms/">project</a>]
              [<a target="_blank" href="https://arxiv.org/pdf/2007.12868.pdf">paper</a>]
              [<a target="_blank" href="https://github.com/ViLab-UCSD/OpenRooms?tab=readme-ov-file">dataset</a>]
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src='images/pubs/2020-eccv-neural-relighting.png' width="110%">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href="https://cseweb.ucsd.edu/~viscomp/projects/ECCV20NeuralRelighting/">
                <papertitle>Single-Shot Neural Relighting and SVBRDF Estimation</papertitle>
              </a>
              <br>
              <strong>Shen Sang</strong>, 
              <a target="_blank" href="https://cseweb.ucsd.edu/~mkchandraker/">Manmohan Chandraker</a>
              <br>
              <br>
                <em>ECCV</em>, 2020
              <br>
              [<a target="_blank" href="https://cseweb.ucsd.edu/~viscomp/projects/ECCV20NeuralRelighting/">project</a>]
              [<a target="_blank" href="pubs/2020-ECCV-NeuralRelighting.pdf">paper</a>]
              [<a target="_blank" href="data/sang2020single.bib">bibtex</a>]
              [<a target="_blank" href="https://github.com/ssangx/NeuralRelighting">code</a>]
            </td>
          </tr>
        </tbody></table>

        <!-- production title -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><b>Products</b></heading>
            </td>
          </tr>
        </tbody></table>

        <!-- product list -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <a id="tiktok-ai-moji"></a>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src='images/products/2024-AI-Moji.png' width="110%">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href=https://www.socialmediatoday.com/news/tiktok-tests-ai-moji-digital-avatars/714522>
                <papertitle>TikTok AI-Moji, 2024</papertitle>
              </a>
            </td>
          </tr>

          <tr>
            <a id="tiktok-ai-self"></a>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src='images/products/2024-TikTok-AISelf-2.jpg' width="110%">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href=https://www.tiktok.com/@wavewyld/video/7325186237533310213?lang=en>
                <papertitle>TikTok AI Self, 2024</papertitle>
              </a>
            </td>
          </tr>

          <tr>
            <a id="tiktok-ai-avatars"></a>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="video-display">
                <video id="video-2023aiavatar" muted src="images/products/2023-AI-Avatars.mp4" type="video/mp4" width="110%">
              </div>
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href=https://www.theverge.com/2023/4/25/23698394/tiktok-ai-profile-picture-avatar-lensa>
                <papertitle>TikTok AI Avatars, 2023</papertitle>
              </a>
            </td>
            <script>
              const video = document.getElementById("video-2023aiavatar");
              video.addEventListener('mouseenter', () => {
                video.controls = true;
              });
              video.addEventListener('mouseleave', () => {
                video.controls = false;
              });
            </script>
          </tr>

          <tr>
            <a id="tiktok-avatars"></a>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <img src='images/products/2022-TikTok-Avatars.jpg' width="110%">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a target="_blank" href=https://newsroom.tiktok.com/en-us/express-yourself-through-tiktok-avatars>
                <papertitle>TikTok Avatars, 2022</papertitle>
              </a>
            </td>
          </tr>
        </tbody></table>

        <!-- service and paper review -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><b>Service</b></heading>
              <p>
                Reviewer: SIGGRAPH 2025, CVPR 2025, CVPR 2024, AAAI 2024, SIGGRAPH Asia 2023, ICCV 2023, CVPR 2023, ICLR 2023, AAAI 2023, TMM, C&G
              </p>
            </td>
          </tr>
        </tbody></table>

        <!-- credit -->
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:center;font-size:small;">
              Credits to this <a target="_blank" href="https://github.com/jonbarron/jonbarron_website">template</a>.
            </p>
          </td>
        </tr>

      </td>
    </tr>
  </table>
</body>

</html>
